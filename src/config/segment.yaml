# @package _global_
defaults:
  - data_gen: null

hydra:
  run:
    dir: ./outputs/${name}/${now:%Y-%m-%d_%H-%M-%S}

name: "default"
seed: 4321

train: True
eval_checkpoint: null

resume_model_only: null

data_seg:
  binary_threshold: 0.5
  image_size: 128
  root: ${env:GANSEG_DATA_SEG_ROOT}
  data:
    - name: 'CUB'
      images_dir: "${data_seg.root}/CUB_200_2011/test_images"
      labels_dir: "${data_seg.root}/CUB_200_2011/test_segmentations"
      crop: True
    - name: 'Flowers'
      images_dir: "${data_seg.root}/Flowers/test_images"
      labels_dir: "${data_seg.root}/Flowers/test_segmentations"
      crop: True
    - name: 'DUT_OMRON'
      images_dir: "${data_seg.root}/DUT_OMRON/DUT-OMRON-image"
      labels_dir: "${data_seg.root}/DUT_OMRON/pixelwiseGT-new-PNG"
      crop: False
    - name: 'DUTS'
      images_dir: "${data_seg.root}/DUTS/DUTS-TE/DUTS-TE-Image"
      labels_dir: "${data_seg.root}/DUTS/DUTS-TE/DUTS-TE-Mask"
      crop: False
    - name: 'ECSSD'
      images_dir: "${data_seg.root}/ECSSD/images"
      labels_dir: "${data_seg.root}/ECSSD/ground_truth_mask"
      crop: False

optimizer: 
  kind: 'Adam'
  lr: 0.001  # maybe should be 1e-4 
  lr_decay_gamma: 0.2
  lr_decay_step_size: 8000

dataloader:
  batch_size: 128
  num_workers: 16

logging:
  log_freq: 100
  log_dir: "logs"
  version: null
  loggers: 
    - 'wandb'

trainer:
  # See https://pytorch-lightning.readthedocs.io/en/stable/trainer.html#trainer-flags
  gpus: 1
  max_steps: 12000
  accelerator: null  # "ddp_spawn"
  num_sanity_val_steps: 5 
  fast_dev_run: False
  resume_from_checkpoint: null
  limit_val_batches: 4
  # val_check_interval: 0.5